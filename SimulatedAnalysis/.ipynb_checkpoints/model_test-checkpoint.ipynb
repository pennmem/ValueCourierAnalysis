{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365c9fb2-f60b-4263-9038-1de3d37cd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../pybeh')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cmlreaders as cml\n",
    "from SimulatedSubjectData import *\n",
    "from pandas_to_pybeh import pd_crp, get_all_matrices\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import os\n",
    "import cmldask.CMLDask as da\n",
    "import cmldask\n",
    "from dask.distributed import wait, as_completed, progress\n",
    "from dask import delayed, compute\n",
    "import logging\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f82caec3-4fd8-45df-bb8b-f221456a8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_len = 15\n",
    "num_lists = 1000\n",
    "\n",
    "exp = 'CourierReinstate1'\n",
    "subjects = ['LTP564', 'LTP565', 'LTP566', 'LTP567', 'LTP568', 'LTP569', 'LTP571', 'LTP572', 'LTP573',\n",
    "            'LTP574', 'LTP575', 'LTP576', 'LTP577', 'LTP578', 'LTP579', 'LTP580', 'LTP581', 'LTP583',\n",
    "            'LTP584', 'LTP585', 'LTP586', 'LTP587', 'LTP588', 'LTP589', 'LTP590', 'LTP591', 'LTP592', \n",
    "            'LTP593', 'LTP594', 'LTP595', 'LTP596', 'LTP597', 'LTP598', 'LTP599', 'LTP600', 'LTP601', \n",
    "            'LTP602', 'LTP603', 'LTP604', 'LTP605']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49a0b06e-d1bf-4389-acd8-f6a84b8f3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"Dictionary saved to {filename}\")\n",
    "\n",
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "240b1922-a26f-46da-9b20-f03cdee72469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cml.get_data_index('ltp', rootdir='/').query(\"experiment == @exp\")\n",
    "\n",
    "full_evs = None\n",
    "for i, row in df.iterrows():\n",
    "    reader = cml.CMLReader(subject=row['subject'], experiment=row['experiment'], session=row['session'])\n",
    "    evs = reader.load('task_events')\n",
    "    full_evs = evs if full_evs is None else pd.concat([full_evs, evs], ignore_index=True)\n",
    "full_evs = full_evs.query(\"subject in @subjects\")\n",
    "full_evs = full_evs[(full_evs['item'] != \"AMPLIFIER\") & (full_evs['item'] != \"APPLE\") & (full_evs['item'] != \"AXE\") & \n",
    "                    (full_evs['item'] != \"BASKETBALL_HOOP\") & (full_evs['item'] != \"DOOR\") & (full_evs['item'] != \"IRONING_BOARD\") & \n",
    "                    (full_evs['item'] != \"SHOVEL\") & (full_evs['item'] != \"STOVE\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1edf6274-b21c-46bc-b244-9d968ee9246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words.pkl\", \"rb\") as f:\n",
    "    wordpool = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3e193a-3a97-4c00-ac5e-3edccafbaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_rate(data):\n",
    "    word_evs = data[data['type'] == 'WORD']\n",
    "    return word_evs['recalled'].sum() / len(word_evs)\n",
    "\n",
    "def compute_first_recall(data, list_len):\n",
    "    rec_evs = data[data['type'] == 'REC_WORD']\n",
    "    rec_evs['pos'] = rec_evs.groupby(['session', 'trial']).cumcount()\n",
    "    first_recall_df = rec_evs.query('pos == 0 and serialpos >= 0')\n",
    "    first_recall_df = first_recall_df.groupby(\n",
    "        ['serialpos']).agg(\n",
    "        {'recalled': 'count'}).reindex(range(1, list_len+1), fill_value=0)\n",
    "    n_lists = first_recall_df['recalled'].sum()\n",
    "    return first_recall_df['recalled'].to_numpy(dtype=float) / n_lists\n",
    "\n",
    "def compute_lag_crp_single_subject_array(\n",
    "    data, \n",
    "    list_len\n",
    "):\n",
    "    center = list_len - 1\n",
    "    min_lag = -center\n",
    "    max_lag = center + 1\n",
    "    actual = {lag: 0 for lag in range(min_lag, max_lag)}\n",
    "    possible = {lag: 0 for lag in range(min_lag, max_lag)}\n",
    "    for session_id, session_data in data.groupby('session'):\n",
    "        recalls = session_data[session_data.type == 'REC_WORD']\n",
    "        # print(recalls)\n",
    "        words = session_data[session_data.type == 'WORD']\n",
    "        if recalls.empty or words.empty:\n",
    "            print(f\"session {session_id} has no events\")\n",
    "            continue\n",
    "        # print(recalls.intruded)\n",
    "        recalls = recalls[(recalls['trial'] != -999)]\n",
    "        word_to_pos = dict(zip(words['item'], words['serialpos']))\n",
    "        # print(word_to_pos)\n",
    "        # print(recalls)\n",
    "        for trial in recalls['trial'].unique():\n",
    "            trial_words = words[words['trial'] == trial]['item'].tolist()\n",
    "            trial_recalls = (recalls[recalls['trial'] == trial]\n",
    "                             .sort_values('rectime')\n",
    "                             .drop_duplicates('item'))\n",
    "            \n",
    "            if len(trial_recalls) < 2:\n",
    "                print(f\"session {session_id}, trial {trial} doesn't have enough events\")\n",
    "                continue\n",
    "            trial_recalls = trial_recalls[trial_recalls['item'].isin(trial_words)]\n",
    "            recall_pos = [word_to_pos[w] for w in trial_recalls['item']]\n",
    "            # print(recall_pos)\n",
    "            for i, cur in enumerate(recall_pos[:-1]):\n",
    "                lag = recall_pos[i+1] - cur\n",
    "                if min_lag <= lag <= max_lag and lag != 0:\n",
    "                    actual[lag] += 1\n",
    "                for pos in set(range(1, list_len+1)) - set(recall_pos[:i+1]):\n",
    "                    pl = pos - cur\n",
    "                    if min_lag <= pl <= max_lag and pl != 0:\n",
    "                        possible[pl] += 1\n",
    "\n",
    "    # build CRP array\n",
    "    full_len = 2*list_len - 1\n",
    "    crp = np.full(full_len, np.nan)\n",
    "    center = list_len - 1\n",
    "    for lag in range(min_lag, max_lag):\n",
    "        idx = center + lag\n",
    "        if 0 <= idx < full_len:\n",
    "            crp[idx] = (actual[lag] / possible[lag]) if possible[lag] > 0 else np.nan\n",
    "    crp[center] = 0.0\n",
    "    return crp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84f4e613-42e8-4bc1-bb36-0d2d0022f6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06382979, 0.05882353, 0.04424779, 0.02898551, 0.06470588,\n",
       "       0.04102564, 0.05479452, 0.04979253, 0.07806691, 0.04895105,\n",
       "       0.06644518, 0.08196721, 0.14195584, 0.3250774 , 0.        ,\n",
       "       0.45721271, 0.20478723, 0.10670732, 0.06713781, 0.06477733,\n",
       "       0.06161137, 0.0483871 , 0.03870968, 0.02459016, 0.04081633,\n",
       "       0.05263158, 0.04081633, 0.        , 0.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df595 = full_evs[full_evs['subject'] == 'LTP595']\n",
    "# compute_recall_rate(df595)\n",
    "# compute_first_recall(df595, list_len)\n",
    "crp595 = compute_lag_crp_single_subject_array(df595, list_len)\n",
    "crp595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8b2b276-6a8d-42be-a395-3fd3c5987f21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session 2, trial 7 doesn't have enough events\n"
     ]
    }
   ],
   "source": [
    "# CourierReinstate1 data\n",
    "sub_parameters = {}\n",
    "\n",
    "for sub in subjects:\n",
    "    df_sub = full_evs[full_evs['subject'] == sub]\n",
    "    recall_rate = compute_recall_rate(df_sub)\n",
    "    first_recall = compute_first_recall(df_sub, list_len)\n",
    "    lag_crp = compute_lag_crp_single_subject_array(df_sub, list_len)\n",
    "    sub_parameters[sub] = {\n",
    "        'recall_rate': recall_rate,\n",
    "        'first_recall': first_recall,\n",
    "        'lag_crp': lag_crp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44b80b80-a74a-4d9d-a2e5-1e9b2342785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def crp_loss(simulated_crp, target_crp):\n",
    "    mask = ~np.isnan(simulated_crp) & ~np.isnan(target_crp)\n",
    "    return np.mean((simulated_crp[mask] - target_crp[mask])**2)\n",
    "\n",
    "def make_objective(sub_id, sub_parameters, target_crp, list_len, num_lists, wordpool, n_avg=3):\n",
    "    \n",
    "    def objective(trial):\n",
    "        # Suggest lag_crp distribution for this subject\n",
    "        lag_crp = np.array([\n",
    "            trial.suggest_float(f\"lag_{i}\", 1e-6, 1.0)\n",
    "            for i in range(len(target_crp))\n",
    "        ])\n",
    "        lag_crp /= lag_crp.sum()  # normalize\n",
    "        # print(lag_crp)\n",
    "        # Pull subject parameters\n",
    "        recall_rate = sub_parameters[sub_id]['recall_rate']\n",
    "        first_recall = sub_parameters[sub_id]['first_recall']\n",
    "\n",
    "        losses = []\n",
    "        for _ in range(n_avg):\n",
    "            sim = SimulatedSubjectData(\n",
    "                subject=sub_id,\n",
    "                first_recall=first_recall,\n",
    "                lag_crp=lag_crp,\n",
    "                recall_rate=recall_rate,\n",
    "                value_acc=0.6,     # if you use this, add to sub_parameters\n",
    "                complex_params=None,     # same here\n",
    "                seed=None\n",
    "            )\n",
    "            df = sim.generateData(list_len, num_lists, num_lists_per_sess=10, wordpool=wordpool, gen_pos=True)\n",
    "            sim_crp = compute_lag_crp_single_subject_array(df, list_len)\n",
    "            losses.append(crp_loss(sim_crp, target_crp))\n",
    "\n",
    "        return np.mean(losses)\n",
    "    return objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60c5739b-dec3-417a-afd1-bbd63df900a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_objective_multi(sub_id, sub_parameters, target_crp, list_len, num_lists, wordpool, n_avg=3):\n",
    "    \"\"\"\n",
    "    Creates a multi-objective Optuna function where each lag's CRP error is a separate objective.\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(trial):\n",
    "        # --- Suggest lag CRP probabilities for each lag ---\n",
    "        lag_crp = np.array([\n",
    "            trial.suggest_float(f\"lag_{i}\", 1e-6, 1.0)\n",
    "            for i in range(len(target_crp))\n",
    "        ])\n",
    "        lag_crp /= lag_crp.sum()  # normalize to sum to 1\n",
    "\n",
    "        # Pull subject-specific parameters\n",
    "        recall_rate = sub_parameters[sub_id]['recall_rate']\n",
    "        first_recall = sub_parameters[sub_id]['first_recall']\n",
    "\n",
    "        # Accumulate per-lag squared errors over n_avg simulations\n",
    "        per_lag_errors = np.zeros(len(target_crp))\n",
    "        for _ in range(n_avg):\n",
    "            sim = SimulatedSubjectData(\n",
    "                subject=sub_id,\n",
    "                first_recall=first_recall,\n",
    "                lag_crp=lag_crp,\n",
    "                recall_rate=recall_rate,\n",
    "                value_acc=0.6,       # optional\n",
    "                complex_params=None, # optional\n",
    "                seed=None\n",
    "            )\n",
    "            df = sim.generateData(list_len, num_lists, num_lists_per_sess=10, wordpool=wordpool, gen_pos=True)\n",
    "            sim_crp = compute_lag_crp_single_subject_array(df, list_len)\n",
    "\n",
    "            mask = ~np.isnan(sim_crp) & ~np.isnan(target_crp)\n",
    "            per_lag_errors[mask] += (sim_crp[mask] - target_crp[mask])**2\n",
    "\n",
    "        # Average across simulations\n",
    "        per_lag_errors /= n_avg\n",
    "\n",
    "        # Return as a tuple: one objective per lag\n",
    "        return tuple(per_lag_errors)\n",
    "\n",
    "    return objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d263d00f-754d-46da-9c93-69452281f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stop_callback(study, trial):\n",
    "    # stop if best loss hasn't improved in the last N trials\n",
    "    if len(study.trials) > 10:  # require minimum trials first\n",
    "        recent_losses = [t.value for t in study.trials[-10:] if t.value is not None]\n",
    "        if max(recent_losses) - min(recent_losses) < 1e-4:  # threshold\n",
    "            print(\"Convergence reached, stopping early\")\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b55e870-63d6-4f68-bba3-94df45505f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Example: pick a subject\n",
    "# sub_id = subjects[0]\n",
    "# target_crp = sub_parameters[sub_id]['lag_crp']  # empirical CRP\n",
    "\n",
    "# # Create Optuna study\n",
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# objective = make_objective(sub_id, sub_parameters, target_crp, list_len=15, num_lists=30, wordpool=wordpool, n_avg=5)\n",
    "# study.optimize(objective, n_trials=100, callbacks=[early_stop_callback])\n",
    "\n",
    "# print(\"Best loss:\", study.best_value)\n",
    "\n",
    "# best_lag_crp = np.array([study.best_params[f\"lag_{i}\"] for i in range(len(target_crp))])\n",
    "# best_lag_crp /= best_lag_crp.sum()\n",
    "# print(\"Best lag_crp distribution:\", best_lag_crp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48dd6164-ba10-4fce-8f87-0cb189af4b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for zrentala is 51618\n",
      "{'dashboard_address': ':51618'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN zrentala@rhino2.psych.upenn.edu -L 8000:192.168.86.108:35389` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    }
   ],
   "source": [
    "# Configure logging at the top of your notebook/script\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# set up slurm \n",
    "logdir = os.path.join(os.path.abspath(os.curdir), 'dask_appendix_logs')\n",
    "# first_run = False\n",
    "dask_args = {'job_name': \"zrentala_workshop4\", 'memory_per_job': \"10GB\", 'max_n_jobs': 20,\n",
    "             'log_directory': './results/Assignment_8/cluster_logs'}\n",
    "os.makedirs(dask_args['log_directory'], exist_ok=True)\n",
    "client = da.new_dask_client(**dask_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68b06d79-924e-47a0-98d6-ec9b6780b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_subject(folder, subject, sub_parameters, obj_params, wordpool):\n",
    "    logger.info(f\"Processing {subject}\")\n",
    "    list_len = obj_params['list_len']\n",
    "    num_lists = obj_params['num_lists']\n",
    "    n_avg = obj_params['n_avg']\n",
    "\n",
    "    target_crp = sub_parameters[subject]['lag_crp']\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    objective = make_objective(subject, sub_parameters, target_crp, list_len=list_len, num_lists=num_lists, wordpool=wordpool, n_avg=n_avg)\n",
    "    study.optimize(objective, n_trials=100, callbacks=[early_stop_callback])\n",
    "\n",
    "    best_lag_crp = np.array([study.best_params[f\"lag_{i}\"] for i in range(len(target_crp))])\n",
    "    best_lag_crp /= best_lag_crp.sum()\n",
    "\n",
    "    results[subject] = {\n",
    "        \"best_loss\": study.best_value,\n",
    "        \"best_lag_crp\": best_lag_crp\n",
    "    }\n",
    "    \n",
    "    save_data(results, f'{folder}/{subject}_optimized.pkl')\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f6dd454-f000-4f5a-ae97-55722f99fd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "folder = 'Optimization_Results'\n",
    "subj_list = subjects\n",
    "sub_params = sub_parameters\n",
    "obj_params ={'list_len': 15, 'num_lists': 100, 'n_avg':5}\n",
    "overwrite = False\n",
    "\n",
    "if overwrite:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    delayed_results = [delayed(optimize_subject)(folder, subj, sub_params, obj_params,wordpool) for subj in subj_list]\n",
    "    results = compute(*delayed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1a57f1c-c03a-4da4-985d-7c06dd74ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = 'Optimization_Results_Multi'\n",
    "# subj_list = ['LTP564']\n",
    "# sub_params = sub_parameters\n",
    "# obj_params = {'list_len': 15, 'num_lists': 10, 'n_avg': 2}\n",
    "# overwrite = True\n",
    "\n",
    "# def optimize_subject_multi(folder, subj_id, sub_params, obj_params, wordpool):\n",
    "#     \"\"\"\n",
    "#     Optimize CRP lag distribution for a single subject using multi-objective Optuna.\n",
    "#     Saves results to folder.\n",
    "#     \"\"\"\n",
    "#     target_crp = sub_params[subj_id]['lag_crp']  # or however you store per-subject target CRP\n",
    "\n",
    "#     # Create multi-objective Optuna study\n",
    "#     n_lags = len(target_crp)\n",
    "#     study = optuna.create_study(\n",
    "#         directions=[\"minimize\"] * n_lags\n",
    "#     )\n",
    "\n",
    "#     # Objective function\n",
    "#     objective_fn = make_objective_multi(\n",
    "#         subj_id,\n",
    "#         sub_params,\n",
    "#         target_crp,\n",
    "#         list_len=obj_params['list_len'],\n",
    "#         num_lists=obj_params['num_lists'],\n",
    "#         wordpool=wordpool,\n",
    "#         n_avg=obj_params.get('n_avg', 3)\n",
    "#     )\n",
    "\n",
    "#     # Optimize\n",
    "#     study.optimize(objective_fn, n_trials=obj_params.get('n_trials', 1))\n",
    "\n",
    "#    # Find best trial (e.g., with lowest mean loss across all objectives)\n",
    "#     best_trial = min(study.best_trials, key=lambda t: np.mean(t.values))\n",
    "#     best_loss = best_trial.values\n",
    "#     best_lag_crp = np.array([best_trial.params[f\"lag_{i}\"] for i in range(n_lags)])\n",
    "#     best_lag_crp /= best_lag_crp.sum()  # normalize to sum to 1\n",
    "\n",
    "#     # Compute aggregate best CRP â€” pick the best per-lag value across all trials\n",
    "#     best_lag_crp_agg = np.zeros(n_lags)\n",
    "#     for i in range(n_lags):\n",
    "#         # Find trial that had the lowest loss for this lag objective\n",
    "#         best_for_lag = min(study.best_trials, key=lambda t: t.values[i])\n",
    "#         best_lag_crp_agg[i] = best_for_lag.params[f\"lag_{i}\"]\n",
    "\n",
    "#     best_lag_crp_agg /= best_lag_crp_agg.sum()  # normalize\n",
    "    \n",
    "#     results[subject] = {\n",
    "#         \"best_loss\": best_loss,\n",
    "#         \"best_lag_crp\": best_lag_crp,\n",
    "#         \"best_lag_crp_agg\": best_lag_crp_agg\n",
    "#     }\n",
    "\n",
    "#     save_data(results, f'{folder}/{subject}_optimized.pkl')\n",
    "\n",
    "#     return results\n",
    "\n",
    "# # Run all subjects in parallel\n",
    "# if overwrite:\n",
    "#     delayed_results = [\n",
    "#         delayed(optimize_subject_multi)(folder, subj, sub_params, obj_params, wordpool)\n",
    "#         for subj in subj_list\n",
    "#     ]\n",
    "#     results = compute(*delayed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "717279b4-9636-4ec5-8e17-0eb6f30c6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_subjects_optimized(folder):\n",
    "    \"\"\"\n",
    "    Loads all {subject}_optimized.pkl files in the folder and combines them into a single dictionary.\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    # find all files ending with _optimized.pkl\n",
    "    files = glob.glob(os.path.join(folder, \"*_optimized.pkl\"))\n",
    "    \n",
    "    for file in files:\n",
    "        with open(file, 'rb') as f:\n",
    "            subject_data = pickle.load(f)  # this is a single dict like {'LTP564': {...}}\n",
    "            # merge into all_data\n",
    "            all_data.update(subject_data)\n",
    "    \n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a9dccd5-f17c-42ed-ad86-e4b2c7d2a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_optimized= load_all_subjects_optimized(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0aba9-7743-4c1f-8483-b09feddd0853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulated data\n",
    "len_lists = 15\n",
    "num_lists = 100\n",
    "sim_dfs = {}\n",
    "\n",
    "for sub, parameters in sub_parameters.items():\n",
    "    best_lag_crp = subj_optimized[sub]['best_lag_crp']\n",
    "    # print(best_lag_crp)\n",
    "    sim = SimulatedSubjectData(\n",
    "        subject=sub,\n",
    "        first_recall=parameters['first_recall'],\n",
    "        lag_crp=best_lag_crp,\n",
    "        recall_rate=parameters['recall_rate'],\n",
    "        value_acc=0.6\n",
    "    )\n",
    "    df_sim = sim.generateData(list_len, num_lists, wordpool=wordpool, gen_pos=True)\n",
    "    # print(df_sim)\n",
    "    sim_dfs[sub] = df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc77d3c-6fe9-40bb-a310-ae1a06077906",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_crps = {}\n",
    "\n",
    "for sub, df_sim in sim_dfs.items():\n",
    "    sim_crps[sub] = compute_lag_crp_single_subject_array(df_sim, list_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a5f2e-d28d-40a8-9faf-5983a36bc667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=8, figsize=(24, 12.5), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "lags = np.arange(-(list_len-1), list_len)\n",
    "mask = lags != 0\n",
    "lags = lags[mask]\n",
    "\n",
    "for ax, sub in zip(axes, sub_parameters.keys()):\n",
    "    cr1_sub_crp = sub_parameters[sub]['lag_crp'][mask]\n",
    "    sim_sub_crp = sim_crps.get(sub)\n",
    "    # sim_sub_crp[len(sim_sub_crp) // 2] = np.nan\n",
    "    # print(sim_sub_crp)\n",
    "    if sim_sub_crp is not None:\n",
    "        sim_sub_crp = sim_sub_crp[mask]\n",
    "        ax.plot(lags, cr1_sub_crp, label=\"CourierReinstate1\")\n",
    "        ax.plot(lags, sim_sub_crp, linestyle=\"--\", label=\"Simulated\")\n",
    "    ax.set_title(str(sub), fontsize=10)\n",
    "    ax.tick_params(labelsize=8)\n",
    "\n",
    "fig.suptitle(\"CR1 vs Simulated Lag CRPs\", fontsize=16)\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f86b8-c7b5-4e99-a221-238d95453afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr1_all_crp = None\n",
    "sim_all_crp = None\n",
    "cr1_stack = np.vstack([sub_parameters[sub]['lag_crp'] for sub in sub_parameters])\n",
    "sim_stack = np.vstack([sim_crps.get(sub) for sub in sub_parameters if sub in sim_crps])\n",
    "cr1_all_crp = cr1_stack.mean(axis=0)\n",
    "sim_all_crp = sim_stack.mean(axis=0)\n",
    "\n",
    "lags = np.arange(-(list_len-1), list_len)\n",
    "# Create a mask for valid values (nonzero lag and non-NaN CRPs)\n",
    "mask = (lags != 0) & (~np.isnan(cr1_all_crp)) & (~np.isnan(sim_all_crp))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(lags[mask], cr1_all_crp[mask], label=\"CourierReinstate1\")\n",
    "plt.plot(lags[mask], sim_all_crp[mask], linestyle=\"--\", label=\"Simulated\")\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Conditional Response Probability')\n",
    "plt.title('Across Subjects Average Lag CRP')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc27262-1536-431c-978a-bb0e91dcbd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {}\n",
    "lags = np.arange(-(list_len-1), list_len)\n",
    "mask = lags != 0\n",
    "lags = lags[mask]\n",
    "        \n",
    "for sub in sub_parameters.keys():\n",
    "    if sub in sim_crps:\n",
    "        cr1_sub_crp = sub_parameters[sub]['lag_crp'][mask]\n",
    "        sim_sub_crp = sim_crps.get(sub)\n",
    "        if sim_sub_crp is not None:\n",
    "            sim_sub_crp = sim_sub_crp[mask]\n",
    "        errors[sub] = np.sqrt(((cr1_sub_crp - sim_sub_crp) ** 2).mean())\n",
    "    \n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5ff36-9a70-46c2-a13e-27402fc3227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_error = np.nanmean(list(errors.values()))\n",
    "avg_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop_311",
   "language": "python",
   "name": "workshop_311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
